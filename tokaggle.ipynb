{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "导入相关的包"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mydataset import MyDataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from unet import UNet\n",
    "import time\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "一些常量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_batch_size = 8\n",
    "batch_size = 8\n",
    "start_epoch = 10\n",
    "epochs = 90\n",
    "lr = 0.001\n",
    "milestones = [25, 50, 75, 100, 125, 150, 175, 200, 250, 300, 400]\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "一些函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def get_model_name(s, lens):\n",
    "    return os.path.join(os.getcwd(), \"saves/U-Net-\" + str(s + lens) + \"th.model\")\n",
    "\n",
    "\n",
    "def get_optimizer_name(s, lens):\n",
    "    return os.path.join(os.getcwd(), \"saves/U-Net-\" + str(s + lens) + \"th.opt\")\n",
    "\n",
    "\n",
    "def get_scheduler_name(s, lens):\n",
    "    return os.path.join(os.getcwd(), \"saves/U-Net-\" + str(s + lens) + \"th.sche\")\n",
    "\n",
    "\n",
    "def get_loss_name_pdf(s, lens):\n",
    "    return os.path.join(os.getcwd(), \"saves/U-Net-\" + str(s + lens) + \"th-loss.pdf\")\n",
    "\n",
    "\n",
    "def get_loss_name_npy():\n",
    "    return os.path.join(os.getcwd(), \"saves/U-Net-loss.npy\")\n",
    "\n",
    "\n",
    "def get_train_iou_npy():\n",
    "    return os.path.join(os.getcwd(), \"saves/U-Net-train-iou.npy\")\n",
    "\n",
    "\n",
    "def get_val_iou_npy():\n",
    "    return os.path.join(os.getcwd(), \"saves/U-Net-val-iou.npy\")\n",
    "\n",
    "\n",
    "def get_iou_pdf(s, lens):\n",
    "    return os.path.join(os.getcwd(), \"saves/U-Net-\" + str(s + lens) + \"th-iou.pdf\")\n",
    "\n",
    "\n",
    "def cal_iou(data_loader, model):\n",
    "    acc_ratios = []\n",
    "    class_values = list(range(9))  # [0, 1, 2. ... 9]\n",
    "    totcnt = [0] * 9\n",
    "    tmp_tot = [0] * 9\n",
    "    for X, Y in data_loader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        Y_pred = model(X)\n",
    "        Y_pred = torch.argmax(Y_pred, dim=1)\n",
    "        for class_value in class_values:\n",
    "            intersection = torch.logical_and(Y == class_value, Y_pred == class_value).sum(dim=(1, 2))\n",
    "            union = torch.logical_or(Y == class_value, Y_pred == class_value).sum(dim=(1, 2))\n",
    "            for i in range(Y.shape[0]):\n",
    "                if union[i] > 0:\n",
    "                    tmp_tot[class_value] += intersection[i] / union[i]\n",
    "                    totcnt[class_value] += 1\n",
    "    for i in class_values:\n",
    "        acc_ratios.append((tmp_tot[i] / totcnt[i]).item())\n",
    "    return acc_ratios\n",
    "\n",
    "\n",
    "def one_hot_encode(label, label_values):\n",
    "    semantic_map = []\n",
    "    for colour in label_values:\n",
    "        equality = np.equal(label, colour) # np.equal实现把label image每个像素的RGB值与某个class的RGB值进行比对，变成RGB bool值\n",
    "        class_map = np.all(equality, axis=-1) # np.all 把RGB bool值，变成一个bool值，即实现某个class 的label mask。使用for循环，生成所有class的label mask\n",
    "        semantic_map.append(class_map)\n",
    "    semantic_map = np.stack(semantic_map, axis=-1) # np.stack实现所有class的label mask的堆叠。最终depth size 为num_classes的数量\n",
    "    return semantic_map\n",
    "\n",
    "def reverse_one_hot(image):\n",
    "    x = np.argmax(image, axis=-1) # axis表示最后一个维度，即channel\n",
    "    return x\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_dir, mask_dir, train_dir):\n",
    "        self.Size = (256, 256)\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_fns = os.listdir(image_dir)\n",
    "        self.mask_fns = os.listdir(mask_dir)\n",
    "        self.class_dict = pd.read_csv(os.path.join(train_dir, 'labels_class_dict.csv'))\n",
    "        # Get class names\n",
    "        self.class_names = self.class_dict['class_names'].tolist()\n",
    "        # Get class RGB values\n",
    "        self.class_rgb_values = self.class_dict[['r', 'g', 'b']].values.tolist()\n",
    "        self.image_preprocessed = []\n",
    "        self.mask_preprocessed = []\n",
    "\n",
    "        for index in range(0, len(self.image_fns)):\n",
    "            image_file_name = self.image_fns[index]\n",
    "            image_path = os.path.join(self.image_dir, image_file_name)\n",
    "            mask_file_name = self.mask_fns[index]\n",
    "            mask_path = os.path.join(self.mask_dir, mask_file_name)\n",
    "            #image = Image.open(image_path).convert('RGB')\n",
    "            image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "            image = np.array(image)\n",
    "            image = self.transform(image)\n",
    "            mask = cv2.cvtColor(cv2.imread(mask_path), cv2.COLOR_BGR2RGB)\n",
    "            #mask = Image.open(mask_path).convert('RGB')\n",
    "            mask = np.array(mask)\n",
    "            mask = one_hot_encode(mask, self.class_rgb_values).astype('float')\n",
    "            mask = reverse_one_hot(mask)\n",
    "            mask = torch.Tensor(mask).long()\n",
    "            mask = mask.unsqueeze(0)  # 升一维\n",
    "            mask_transform = transforms.Resize(size=self.Size, interpolation=InterpolationMode.NEAREST)\n",
    "            mask = mask_transform(mask)\n",
    "            mask = mask.squeeze(0)  # 还原维度\n",
    "            self.image_preprocessed.append(image)\n",
    "            self.mask_preprocessed.append(mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_fns)\n",
    "\n",
    "    def transform(self, image):\n",
    "        transform_ops = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            transforms.Resize(size=self.Size, interpolation=InterpolationMode.NEAREST)\n",
    "        ])\n",
    "        return transform_ops(image)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.image_preprocessed[index], self.mask_preprocessed[index]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "设置目录"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "train_dir = os.path.join(os.getcwd(), \"new_data\", \"train\")\n",
    "image_dir = os.path.join(train_dir, \"images\")\n",
    "mask_dir = os.path.join(train_dir, \"masks\")\n",
    "train_dataset = MyDataset(image_dir=image_dir, mask_dir=mask_dir, train_dir=train_dir)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "val_dir = os.path.join(os.getcwd(), \"new_data\", \"val\")\n",
    "image_dir = os.path.join(val_dir, \"images\")\n",
    "mask_dir = os.path.join(val_dir, \"masks\")\n",
    "test_dataset = MyDataset(image_dir=image_dir, mask_dir=mask_dir, train_dir=val_dir)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=test_batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "加载上次的模型与loss数据"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = UNet(num_classes=9).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.5)\n",
    "epoch_losses = []\n",
    "train_iou_arr = []\n",
    "val_iou_arr = []\n",
    "if start_epoch > 0:\n",
    "    model.load_state_dict(torch.load(get_model_name(start_epoch, 0)))\n",
    "    optimizer.load_state_dict(torch.load(get_optimizer_name(start_epoch, 0)))\n",
    "    scheduler.load_state_dict(torch.load(get_scheduler_name(start_epoch, 0)))\n",
    "    if os.path.exists(get_loss_name_npy()):\n",
    "        epoch_losses = np.load(get_loss_name_npy()).tolist()\n",
    "    if os.path.exists(get_train_iou_npy()):\n",
    "        train_iou_arr = np.load(get_train_iou_npy()).tolist()\n",
    "    if os.path.exists(get_val_iou_npy()):\n",
    "        val_iou_arr = np.load(get_val_iou_npy()).tolist()\n",
    "epoch_losses = epoch_losses[:start_epoch]\n",
    "train_iou_arr = train_iou_arr[:start_epoch]\n",
    "val_iou_arr = val_iou_arr[:start_epoch]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "开始训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1  # start from 1\n",
    "    print(\"on iteration:\" + str(start_epoch + epoch))\n",
    "    start_time = time.time()\n",
    "    epoch_loss = 0\n",
    "    for X, Y in train_data_loader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X)\n",
    "        loss = criterion(Y_pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_losses.append(epoch_loss / len(train_data_loader))\n",
    "\n",
    "    # 每次迭代计算训练集和验证集的iou\n",
    "    cur_train_iou = cal_iou(train_data_loader, model)\n",
    "    cur_val_iou = cal_iou(test_data_loader, model)\n",
    "    train_iou_arr.append(cur_train_iou)\n",
    "    val_iou_arr.append(cur_val_iou)\n",
    "    # 保存模型与数据\n",
    "    if (start_epoch + epoch) % 20 == 0:\n",
    "        torch.save(model.state_dict(), get_model_name(start_epoch, epoch))\n",
    "        torch.save(optimizer.state_dict(), get_optimizer_name(start_epoch, epoch))\n",
    "        torch.save(scheduler.state_dict(), get_scheduler_name(start_epoch, epoch))\n",
    "\n",
    "    np.save(get_loss_name_npy(), epoch_losses)\n",
    "    np.save(get_train_iou_npy(), train_iou_arr)\n",
    "    np.save(get_val_iou_npy(), val_iou_arr)\n",
    "\n",
    "    scheduler.step()\n",
    "    end_time = time.time()\n",
    "    print(\"curt: \" + str(end_time - start_time) + \"/s\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "打印并保存loss图"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axe = plt.subplots(figsize=(10, 10))\n",
    "x_axe = list(range(start_epoch + epochs))\n",
    "x_axe = [i + 1 for i in x_axe]\n",
    "axe.plot(x_axe, epoch_losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "axe.set_title('loss lr=' + str(lr))\n",
    "plt.savefig(get_loss_name_pdf(start_epoch, epochs))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "打印并保存iou图"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig2, axes2 = plt.subplots(3, 3, figsize=(15, 15))\n",
    "plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        axes2[row, col].plot(x_axe, [x[row * 3 + col] for x in train_iou_arr])\n",
    "        axes2[row, col].plot(x_axe, [x[row * 3 + col] for x in val_iou_arr])\n",
    "        axes2[row, col].set_title(\"IOU of class \" + str(row * 3 + col))\n",
    "        axes2[row, col].legend(['train', 'val'])\n",
    "plt.savefig(get_iou_pdf(start_epoch, epochs))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
