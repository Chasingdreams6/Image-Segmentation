{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6634b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mydataset import MyDataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from unet import UNet\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6842fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_dir, mask_dir, train_dir):\n",
    "        self.Size = (256, 256)\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_fns = os.listdir(image_dir)\n",
    "        self.mask_fns = os.listdir(mask_dir)\n",
    "        self.class_dict = pd.read_csv(os.path.join(train_dir, 'labels_class_dict.csv'))\n",
    "        # Get class names\n",
    "        self.class_names = self.class_dict['class_names'].tolist()\n",
    "        # Get class RGB values\n",
    "        self.class_rgb_values = self.class_dict[['r', 'g', 'b']].values.tolist()\n",
    "        self.image_preprocessed = []\n",
    "        self.mask_preprocessed = []\n",
    "\n",
    "        for index in range(0, len(self.image_fns)):\n",
    "            image_file_name = self.image_fns[index]\n",
    "            image_path = os.path.join(self.image_dir, image_file_name)\n",
    "            mask_file_name = self.mask_fns[index]\n",
    "            mask_path = os.path.join(self.mask_dir, mask_file_name)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = np.array(image)\n",
    "            image = self.transform(image)\n",
    "            mask = Image.open(mask_path).convert('RGB')\n",
    "            mask = np.array(mask)\n",
    "            mask = one_hot_encode(mask, self.class_rgb_values).astype('float')\n",
    "            mask = reverse_one_hot(mask)\n",
    "            mask = torch.Tensor(mask).long()\n",
    "            mask = mask.unsqueeze(0)  # 升一维\n",
    "            mask_transform = transforms.Resize(size=self.Size)\n",
    "            mask = mask_transform(mask)\n",
    "            mask = mask.squeeze(0)  # 还原维度\n",
    "            self.image_preprocessed.append(image)\n",
    "            self.mask_preprocessed.append(mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_fns)\n",
    "\n",
    "    def transform(self, image):\n",
    "        transform_ops = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            transforms.Resize(size=self.Size)\n",
    "        ])\n",
    "        return transform_ops(image)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.image_preprocessed[index], self.mask_preprocessed[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e842b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.contracting_11 = self.conv_block(in_channels=3, out_channels=64)\n",
    "        self.contracting_12 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.contracting_21 = self.conv_block(in_channels=64, out_channels=128)\n",
    "        self.contracting_22 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.contracting_31 = self.conv_block(in_channels=128, out_channels=256)\n",
    "        self.contracting_32 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.contracting_41 = self.conv_block(in_channels=256, out_channels=512)\n",
    "        self.contracting_42 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.middle = self.conv_block(in_channels=512, out_channels=1024)\n",
    "        self.expansive_11 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=3, stride=2, padding=1,\n",
    "                                               output_padding=1)\n",
    "        self.expansive_12 = self.conv_block(in_channels=1024, out_channels=512)\n",
    "        self.expansive_21 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1,\n",
    "                                               output_padding=1)\n",
    "        self.expansive_22 = self.conv_block(in_channels=512, out_channels=256)\n",
    "        self.expansive_31 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1,\n",
    "                                               output_padding=1)\n",
    "        self.expansive_32 = self.conv_block(in_channels=256, out_channels=128)\n",
    "        self.expansive_41 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1,\n",
    "                                               output_padding=1)\n",
    "        self.expansive_42 = self.conv_block(in_channels=128, out_channels=64)\n",
    "        self.output = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=out_channels))\n",
    "        return block\n",
    "\n",
    "    def forward(self, X):\n",
    "        contracting_11_out = self.contracting_11(X)  # [-1, 64, 256, 256]\n",
    "        contracting_12_out = self.contracting_12(contracting_11_out)  # [-1, 64, 128, 128]\n",
    "        contracting_21_out = self.contracting_21(contracting_12_out)  # [-1, 128, 128, 128]\n",
    "        contracting_22_out = self.contracting_22(contracting_21_out)  # [-1, 128, 64, 64]\n",
    "        contracting_31_out = self.contracting_31(contracting_22_out)  # [-1, 256, 64, 64]\n",
    "        contracting_32_out = self.contracting_32(contracting_31_out)  # [-1, 256, 32, 32]\n",
    "        contracting_41_out = self.contracting_41(contracting_32_out)  # [-1, 512, 32, 32]\n",
    "        contracting_42_out = self.contracting_42(contracting_41_out)  # [-1, 512, 16, 16]\n",
    "        middle_out = self.middle(contracting_42_out)  # [-1, 1024, 16, 16]\n",
    "        expansive_11_out = self.expansive_11(middle_out)  # [-1, 512, 32, 32]\n",
    "        expansive_12_out = self.expansive_12(\n",
    "            torch.cat((expansive_11_out, contracting_41_out), dim=1))  # [-1, 1024, 32, 32] -> [-1, 512, 32, 32]\n",
    "        expansive_21_out = self.expansive_21(expansive_12_out)  # [-1, 256, 64, 64]\n",
    "        expansive_22_out = self.expansive_22(\n",
    "            torch.cat((expansive_21_out, contracting_31_out), dim=1))  # [-1, 512, 64, 64] -> [-1, 256, 64, 64]\n",
    "        expansive_31_out = self.expansive_31(expansive_22_out)  # [-1, 128, 128, 128]\n",
    "        expansive_32_out = self.expansive_32(\n",
    "            torch.cat((expansive_31_out, contracting_21_out), dim=1))  # [-1, 256, 128, 128] -> [-1, 128, 128, 128]\n",
    "        expansive_41_out = self.expansive_41(expansive_32_out)  # [-1, 64, 256, 256]\n",
    "        expansive_42_out = self.expansive_42(\n",
    "            torch.cat((expansive_41_out, contracting_11_out), dim=1))  # [-1, 128, 256, 256] -> [-1, 64, 256, 256]\n",
    "        output_out = self.output(expansive_42_out)  # [-1, num_classes, 256, 256]\n",
    "        return output_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b9586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(label, label_values):\n",
    "    semantic_map = []\n",
    "    for colour in label_values:\n",
    "        equality = np.equal(label, colour) # np.equal实现把label image每个像素的RGB值与某个class的RGB值进行比对，变成RGB bool值\n",
    "        class_map = np.all(equality, axis=-1) # np.all 把RGB bool值，变成一个bool值，即实现某个class 的label mask。使用for循环，生成所有class的label mask\n",
    "        semantic_map.append(class_map)\n",
    "    semantic_map = np.stack(semantic_map, axis=-1) # np.stack实现所有class的label mask的堆叠。最终depth size 为num_classes的数量\n",
    "    return semantic_map\n",
    "\n",
    "def reverse_one_hot(image):\n",
    "    x = np.argmax(image, axis=-1) # axis表示最后一个维度，即channel\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
